{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ab3514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b9234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    " \"Rafael Nadal Joins Roger Federer in Missing U.S. Open\",\n",
    " \"Rafael Nadal Is Out of the Australian Open\",\n",
    " \"Biden Announces Virus Measures\",\n",
    " \"Biden's Virus Plans Meet Reality\",\n",
    " \"Where Biden's Virus Plan Stands\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a728b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rafael', 'nadal', 'join', 'roger', 'federer', 'missing', 'open'],\n",
       " ['rafael', 'nadal', 'australian', 'open'],\n",
       " ['biden', 'announces', 'virus', 'measure'],\n",
       " ['biden', 'virus', 'plan', 'meet', 'reality'],\n",
       " ['biden', 'virus', 'plan', 'stand']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocessed_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalnum()]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "preprocessed_documents = [preprocessed_text(doc) for doc in documents]\n",
    "preprocessed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a4ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Gensim distionary object from the preprocessed documents\n",
    "dictionary = corpora.Dictionary(preprocessed_documents)\n",
    "\n",
    "#convert each preprocessed document into a BoW representation using the dictionary\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "005eac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus: BoW representation of the doc\n",
    "#num_topics: num of topics to be extracted by the model\n",
    "#id2word=dictionary: dictionary mapping from word IDs to words\n",
    "#passes: num of passes through the corpus during the training\n",
    "#train the LDA model on the corpus with 4 topics using gensim LdaModelclass\n",
    "lda_model = LdaModel(corpus, num_topics=2, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4499a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list to store dominiant topic labels for each doc\n",
    "article_labels = []\n",
    "\n",
    "#iterate over each preprocessed document\n",
    "for i, doc in enumerate(preprocessed_documents):\n",
    "    #for each doc, convert to box representation\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    \n",
    "    #get list of topic probabilities\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    \n",
    "    #determine the topic with highest probability\n",
    "    dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "    \n",
    "    #append to the list\n",
    "    article_labels.append(dominant_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fed8f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with Articles and Topic:\n",
      "                                             Article  Topic\n",
      "0  Rafael Nadal Joins Roger Federer in Missing U....      0\n",
      "1         Rafael Nadal Is Out of the Australian Open      0\n",
      "2                     Biden Announces Virus Measures      1\n",
      "3                   Biden's Virus Plans Meet Reality      1\n",
      "4                    Where Biden's Virus Plan Stands      1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#create dataframe\n",
    "df = pd.DataFrame({\"Article\": documents, \"Topic\": article_labels})\n",
    "\n",
    "#print the dataframe\n",
    "print(\"Table with Articles and Topic:\")\n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d29cb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terns for each Topic:\n",
      "Topic 0:\n",
      "- \"rafael\" (weight: 0.127)\n",
      "- \"open\" (weight: 0.127)\n",
      "- \"nadal\" (weight: 0.127)\n",
      "- \"missing\" (weight: 0.076)\n",
      "- \"federer\" (weight: 0.076)\n",
      "- \"join\" (weight: 0.076)\n",
      "- \"roger\" (weight: 0.076)\n",
      "- \"australian\" (weight: 0.076)\n",
      "- \"measure\" (weight: 0.036)\n",
      "- \"announces\" (weight: 0.036)\n",
      "\n",
      "Topic 1:\n",
      "- \"biden\" (weight: 0.167)\n",
      "- \"virus\" (weight: 0.167)\n",
      "- \"plan\" (weight: 0.122)\n",
      "- \"meet\" (weight: 0.073)\n",
      "- \"reality\" (weight: 0.073)\n",
      "- \"stand\" (weight: 0.073)\n",
      "- \"announces\" (weight: 0.063)\n",
      "- \"measure\" (weight: 0.063)\n",
      "- \"australian\" (weight: 0.025)\n",
      "- \"nadal\" (weight: 0.025)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print the top terms for each topic\n",
    "print(\"Top terns for each Topic:\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {idx}:\")\n",
    "    terms = [term.strip() for term in topic.split(\"+\")]\n",
    "    for term in terms:\n",
    "        weight, word = term.split(\"*\")\n",
    "        print(f\"- {word.strip()} (weight: {weight.strip()})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b6a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
